diff --git a/dist/experimental/llms/chrome_ai.js b/dist/experimental/llms/chrome_ai.js
index 044ad31e2cf97887e24303de1c73d8351d5c5d4d..df392b8128d0e75f3da40a587d4e4fa7e3ab3652 100644
--- a/dist/experimental/llms/chrome_ai.js
+++ b/dist/experimental/llms/chrome_ai.js
@@ -74,20 +74,20 @@ export class ChromeAI extends LLM {
         try {
             // eslint-disable-next-line @typescript-eslint/ban-ts-comment
             // @ts-ignore Experimental browser-only global
-            aiInstance = ai;
+            aiInstance = LanguageModel;
             // eslint-disable-next-line @typescript-eslint/no-explicit-any
         }
         catch (e) {
             throw new Error(`Could not initialize ChromeAI instance. Make sure you are running a version of Chrome with the proper experimental flags enabled.\n\nError message: ${e.message}`);
         }
-        const { available } = await aiInstance.languageModel.capabilities();
-        if (available === "no") {
+        const availability = await aiInstance.availability();
+        if (availability === "no") {
             throw new Error("The AI model is not available.");
         }
-        else if (available === "after-download") {
+        else if (availability === "after-download") {
             throw new Error("The AI model is not yet downloaded.");
         }
-        const session = await aiInstance.languageModel.create({
+        const session = await aiInstance.create({
             systemPrompt: this.systemPrompt,
             topK: this.topK,
             temperature: this.temperature,
@@ -99,7 +99,7 @@ export class ChromeAI extends LLM {
         try {
             session = await this.createSession();
             const stream = session.promptStreaming(prompt);
-            const iterableStream = 
+            const iterableStream =
             // eslint-disable-next-line @typescript-eslint/no-explicit-any
             IterableReadableStream.fromReadableStream(stream);
             let previousContent = "";

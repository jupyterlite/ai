{
  "Chat and completer provider": "Fournisseur de chat et de compléteur",
  "Chat provider": "Fournisseur de chat",
  "Completer provider": "Fournisseur de compléteur",
  "The provider registry is needed to enable the jupyterlite-ai settings panel": "Le registre des fournisseurs est nécessaire pour activer le panneau des paramètres de jupyterlite-ai",
  "The provider is missing from the completer settings": "Le fournisseur est manquant dans les paramètres du compléteur",
  "The AI provider to use for chat and completion": "Le fournisseur d'IA à utiliser pour le chat et la complétion",
  "The provider is missing from the chat settings": "Le fournisseur est manquant dans les paramètres du chat",
  "Instructions": "Instructions",
  "Restore to Defaults": "Restaurer les valeurs par défaut",
  "Stop streaming": "Arrêter le streaming",
  "#### Ask JupyterLite AI": "#### Demander à JupyterLite AI",
  "The provider to use can be set in the": "Le fournisseur à utiliser peut être défini dans l'",
  "settings editor": "éditeur de paramètres",
  "by selecting it from the": "en le sélectionnant depuis les",
  "_AI provider_ settings": "paramètres _Fournisseur d'IA_",
  "The current providers that are available are": "Les fournisseurs actuellement disponibles sont",
  "To clear the chat, you can use the": "Pour effacer le chat, vous pouvez utiliser la",
  "command from the chat input": "commande depuis l'entrée du chat",
  "AI provider not configured": "Fournisseur d'IA non configuré",
  "/clear": "/effacer",
  "Clear the chat": "Effacer le chat",
  "A AI provider named '%1' is already registered": "Un fournisseur d'IA nommé '%1' est déjà enregistré",
  "Autocompletion registry": "Registre d'autocomplétion",
  "LLM chat extension": "Extension de chat LLM",
  "The SettingsRegistry is not loaded for the chat extension": "Le SettingsRegistry n'est pas chargé pour l'extension de chat",
  "Something went wrong when reading the settings.\n%1": "Quelque chose s'est mal passé lors de la lecture des paramètres.\n%1",
  "Jupyterlite AI Chat": "Chat JupyterLite AI",
  "Failed to load settings for %1": "Échec du chargement des paramètres pour %1",
  "AI provider": "Fournisseur d'IA",
  "Provider settings": "Paramètres du fournisseur",
  "Support for ChromeAI is still experimental and only available in Google Chrome.": "Le support de ChromeAI est encore expérimental et uniquement disponible dans Google Chrome.",
  "You can test ChromeAI is enabled in your browser by going to the following URL:": "Vous pouvez tester si ChromeAI est activé dans votre navigateur en accédant à l'URL suivante :",
  "Enable the proper flags in Google Chrome.": "Activez les drapeaux appropriés dans Google Chrome.",
  "Then restart Chrome for these changes to take effect.": "Redémarrez ensuite Chrome pour que ces modifications prennent effet.",
  "On first use, Chrome will download the on-device model, which can be as large as 22GB (according to their docs and at the time of writing).": "À la première utilisation, Chrome téléchargera le modèle sur appareil, qui peut faire jusqu'à 22 Go (selon leur documentation et au moment de l'écriture).",
  "During the download, ChromeAI may not be available via the extension.": "Pendant le téléchargement, ChromeAI peut ne pas être disponible via l'extension.",
  "For more information about Chrome Built-in AI:": "Pour plus d'informations sur l'IA intégrée de Chrome :",
  "Your browser does not support ChromeAI. Please use an updated chrome based browser like Google Chrome, and follow the instructions in settings to enable it.": "Votre navigateur ne supporte pas ChromeAI. Veuillez utiliser un navigateur basé sur Chrome à jour comme Google Chrome, et suivez les instructions dans les paramètres pour l'activer.",
  "The ChromeAI model is not available in your browser. Please ensure you have enabled the necessary flags in Google Chrome as described in the instructions in settings.": "Le modèle ChromeAI n'est pas disponible dans votre navigateur. Veuillez vous assurer d'avoir activé les drapeaux nécessaires dans Google Chrome comme décrit dans les instructions des paramètres.",
  "This extension is still very much experimental. It is not an official Google extension.": "Cette extension est encore très expérimentale. Ce n'est pas une extension officielle de Google.",
  "Go to <https://aistudio.google.com> and create an API key.": "Allez sur <https://aistudio.google.com> et créez une clé API.",
  "Open the JupyterLab settings and go to the **Ai providers** section to select the `Gemini` provider and add your API key (required).": "Ouvrez les paramètres de JupyterLab et allez dans la section **Fournisseurs d'IA** pour sélectionner le fournisseur `Gemini` et ajouter votre clé API (obligatoire).",
  "Open the chat, or use the inline completer.": "Ouvrez le chat, ou utilisez le compléteur en ligne.",
  "This extension is still very much experimental. It is not an official MistralAI extension.": "Cette extension est encore très expérimentale. Ce n'est pas une extension officielle de MistralAI.",
  "Go to <https://console.mistral.ai/api-keys/> and create an API key.": "Allez sur <https://console.mistral.ai/api-keys/> et créez une clé API.",
  "Open the JupyterLab settings and go to the **Ai providers** section to select the `MistralAI` provider and the API key (required).": "Ouvrez les paramètres de JupyterLab et allez dans la section **Fournisseurs d'IA** pour sélectionner le fournisseur `MistralAI` et la clé API (obligatoire).",
  "**Note:** When using MistralAI for completions, only a subset of models are available. Please check [this resource](https://docs.mistral.ai/api/#tag/fim) to see the list of supported models for completions.": "**Note :** Lors de l'utilisation de MistralAI pour les complétions, seul un sous-ensemble de modèles est disponible. Veuillez vérifier [cette ressource](https://docs.mistral.ai/api/#tag/fim) pour voir la liste des modèles supportés pour les complétions.",
  "Open the chat, or use the inline completer": "Ouvrez le chat, ou utilisez le compléteur en ligne",
  "Ollama allows to run large language models locally on your machine.": "Ollama permet d'exécuter de grands modèles de langage localement sur votre machine.",
  "To use it you need to install the Ollama CLI and pull the model you want to use.": "Pour l'utiliser, vous devez installer la CLI Ollama et télécharger le modèle que vous souhaitez utiliser.",
  "Install the Ollama CLI by following the instructions at <https://ollama.com/download>": "Installez la CLI Ollama en suivant les instructions sur <https://ollama.com/download>",
  "Pull the model you want to use by running the following command in your terminal:": "Téléchargez le modèle que vous souhaitez utiliser en exécutant la commande suivante dans votre terminal :",
  "For example, to pull the Llama 2 model, run:": "Par exemple, pour télécharger le modèle Llama 2, exécutez :",
  "Once the model is pulled, you can use it in your application by running the following command:": "Une fois le modèle téléchargé, vous pouvez l'utiliser dans votre application en exécutant la commande suivante :",
  "This model will be available in the extension, using the model name you used in the command above.": "Ce modèle sera disponible dans l'extension, en utilisant le nom de modèle que vous avez utilisé dans la commande ci-dessus.",
  "Deploying Lite/Lab on external server": "Déploiement de Lite/Lab sur un serveur externe",
  "See https://objectgraph.com/blog/ollama-cors/ for more details.": "Voir https://objectgraph.com/blog/ollama-cors/ pour plus de détails.",
  "On Linux, you can run the following commands:": "Sur Linux, vous pouvez exécuter les commandes suivantes :",
  "Check if CORS is enabled on the server. You can do this by running the following command in your terminal:": "Vérifiez si CORS est activé sur le serveur. Vous pouvez le faire en exécutant la commande suivante dans votre terminal :",
  "If CORS is disabled, you will see a response like this:": "Si CORS est désactivé, vous verrez une réponse comme celle-ci :",
  "If CORS is not enabled, update _/etc/systemd/system/ollama.service_ with:": "Si CORS n'est pas activé, mettez à jour _/etc/systemd/system/ollama.service_ avec :",
  "Restart the service:": "Redémarrez le service :",
  "Check if CORS is enabled on the server again by running the following command in your terminal:": "Vérifiez à nouveau si CORS est activé sur le serveur en exécutant la commande suivante dans votre terminal :",
  "WebLLM enables running LLMs directly in your browser, making it possible to use AI features without sending data to external servers.": "WebLLM permet d'exécuter des LLM directement dans votre navigateur, permettant d'utiliser les fonctionnalités d'IA sans envoyer de données vers des serveurs externes.",
  "WebLLM runs models entirely in your browser, so initial model download may be large (100MB-2GB depending on the model).": "WebLLM exécute les modèles entièrement dans votre navigateur, donc le téléchargement initial du modèle peut être important (100MB-2GB selon le modèle).",
  "**Requirements:** WebLLM requires a browser with WebGPU support (Chrome 113+, Edge 113+, or Safari 17+). It will not work on older browsers or browsers without WebGPU enabled.": "**Exigences :** WebLLM nécessite un navigateur avec support WebGPU (Chrome 113+, Edge 113+, ou Safari 17+). Il ne fonctionnera pas sur les navigateurs plus anciens ou les navigateurs sans WebGPU activé.",
  "Enter a model in the JupyterLab settings under the **Ai providers** section. Select the `WebLLM` provider and type the model you want to use.": "Entrez un modèle dans les paramètres de JupyterLab sous la section **Fournisseurs d'IA**. Sélectionnez le fournisseur `WebLLM` et tapez le modèle que vous souhaitez utiliser.",
  "When you first use WebLLM, your browser will download the model. A progress notification will appear:": "Quand vous utilisez WebLLM pour la première fois, votre navigateur téléchargera le modèle. Une notification de progression apparaîtra :",
  "Once loaded, use the chat": "Une fois chargé, utilisez le chat",
  "Example of available models:": "Exemple de modèles disponibles :",
  "See the full list of models: https://github.com/mlc-ai/web-llm/blob/632d34725629b480b5b2772379ef5c150b1286f0/src/config.ts#L303-L309": "Voir la liste complète des modèles : https://github.com/mlc-ai/web-llm/blob/632d34725629b480b5b2772379ef5c150b1286f0/src/config.ts#L303-L309",
  "Model performance depends on your device's hardware capabilities. More powerful devices will run models faster. Some larger models may not work well on devices with limited GPU memory or may experience slow response times.": "Les performances du modèle dépendent des capacités matérielles de votre appareil. Les appareils plus puissants exécuteront les modèles plus rapidement. Certains modèles plus grands peuvent ne pas bien fonctionner sur des appareils avec une mémoire GPU limitée ou peuvent subir des temps de réponse lents.",
  "Your browser does not support WebLLM, it does not support required WebGPU.": "Votre navigateur ne supporte pas WebLLM, il ne supporte pas WebGPU requis.",
  "You may need to enable WebGPU, `await navigator.gpu.requestAdapter()` is null.": "Vous devrez peut-être activer WebGPU, `await navigator.gpu.requestAdapter()` est null."
}
